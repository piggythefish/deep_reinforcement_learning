{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "import cv2\n",
    "\n",
    "GAMMA = 0.99\n",
    "TAU = 0.01\n",
    "BATCHSIZE = 128\n",
    "N_BATCHES = 64\n",
    "N_MULTI_ENVS = 62\n",
    "EXPLORATION_RATE = 0.22\n",
    "EPSILON_DECAY = 0.9999\n",
    "\n",
    "N_NEW_SAMPLES = 500\n",
    "N_SAMPLE_SETS = 100\n",
    "\n",
    "CHECKPOINT_FREQ = 100\n",
    "LOG_FREQ = 100\n",
    "N_TEST_ENVS = 8\n",
    "ENV_NAME = 'ALE/Breakout-v5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "x = np.arange(20000)\n",
    "y = EXPLORATION_RATE * (EPSILON_DECAY ** x)\n",
    "y = np.maximum(y, 0.1)\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.title(\"Epsilon over time\")\n",
    "plt.xlabel(\"Outer Loop Iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMP_SAVE_TO_PATH = \"breakout/ckps/ckpt\"\n",
    "TMP_LOG_PATH = \"breakout/logs/{}.json\"\n",
    "TB_LOGS = \"breakout/tb_lobs/run\"\n",
    "\n",
    "\n",
    "os.makedirs(TMP_SAVE_TO_PATH.replace(\"/ckpt\",\"\"), exist_ok= True)\n",
    "os.makedirs(TMP_LOG_PATH.replace(\"/{}.json\",\"\"), exist_ok= True)\n",
    "os.makedirs(TB_LOGS, exist_ok= True)\n",
    "\n",
    "# # get old checkpoint\n",
    "# !cp /content/gdrive/MyDrive/DeepRL/HW4/checkpoint.zip checkpoint.zip\n",
    "# !unzip -d {TMP_SAVE_TO_PATH} checkpoint.zip\n",
    "\n",
    "LOSS = tf.keras.losses.Huber()\n",
    "CNN_SHAPE = (84, 84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triple_conv_block_no_batchnorm(x, filters):\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        filters, 3, padding='same', activation='relu')(x)\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        filters, 3, padding='same', activation='relu')(x) + x\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        filters, 3, padding='same', activation='relu')(x) + x\n",
    "\n",
    "    return x\n",
    "\n",
    "def get_small_dqn():\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    inputs = tf.keras.layers.Input((84, 84, 4,))\n",
    "    x = triple_conv_block_no_batchnorm(inputs, 10)\n",
    "    x = tf.keras.layers.MaxPool2D(2)(x)\n",
    "    x = triple_conv_block_no_batchnorm(x, 20)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dense(512, \"relu\")(x)\n",
    "    outputs = tf.keras.layers.Dense(4, \"linear\")(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"standard_dqn\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def sample_trajectory(dqn, state, epsilon=0.2):\n",
    "\n",
    "    n_par = tf.shape(state)[0]\n",
    "\n",
    "    mask = tf.random.uniform((n_par,), 0, 1, tf.float32) > epsilon\n",
    "\n",
    "    predictions = dqn(state, training=False)\n",
    "    max_actions = tf.math.argmax(predictions, axis=-1)\n",
    "\n",
    "    random_choices = tf.random.uniform(\n",
    "        shape=[n_par], minval=0, maxval=4, dtype=tf.int64)\n",
    "\n",
    "    return tf.where(mask, max_actions, random_choices), tf.reduce_max(predictions, -1)\n",
    "\n",
    "\n",
    "class ENV_SAMPLER:\n",
    "    \"\"\"\n",
    "    Class for sampling environment data using a DQN model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dqn, n_multi_envs, stack_frames = 4) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the ENV_SAMPLER instance.\n",
    "\n",
    "        Args:\n",
    "            env: The environment to sample from.\n",
    "            dqn: The DQN model for action selection.\n",
    "            n_multi_envs: The number of parallel environments.\n",
    "            preprocess_observation: Function to preprocess observations.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.env = gym.vector.make(ENV_NAME, num_envs=n_multi_envs)\n",
    "        self.dqn = dqn\n",
    "        self.n_multi_envs = n_multi_envs\n",
    "        self.stack_frames = stack_frames\n",
    "        self.current_state = self.env.reset()[0]\n",
    "        \n",
    "        self.frames = [deque([self.process_frame(init_frame) for _ in range(4)]) for init_frame in self.current_state]\n",
    "        \n",
    "        self.last_observation = self.frames_to_stacked_ar()        \n",
    "\n",
    "    \n",
    "    def process_frame(self, frame):\n",
    "        \n",
    "        frame = cv2.cvtColor(np.float32(frame), cv2.COLOR_RGB2GRAY)\n",
    "        frame = cv2.resize(\n",
    "            frame, (84, 84), interpolation=cv2.INTER_AREA\n",
    "        )\n",
    "        return frame\n",
    "        \n",
    "    def frames_to_stacked_ar(self):\n",
    "        \n",
    "        res = []\n",
    "        \n",
    "        for que in self.frames:\n",
    "            \n",
    "            obs = np.stack(list(que), -1)\n",
    "            res.append(obs)\n",
    "            \n",
    "        return np.stack(res, 0)\n",
    "            \n",
    "        \n",
    "    def step(self, actions):\n",
    "        \n",
    "        observation, reward, terminated, truncated, info = self.env.step(actions)\n",
    "        \n",
    "        for obs, ter, que in zip(observation, reward, self.frames):\n",
    "            \n",
    "            # if terminated set all frames to be reset frames\n",
    "            \n",
    "            obs = self.process_frame(obs)\n",
    "            \n",
    "            if ter:\n",
    "                \n",
    "                que = deque([obs for _ in range(4)])\n",
    "                \n",
    "            que.popleft()\n",
    "            \n",
    "            que.append(obs)\n",
    "            \n",
    "        observation = self.frames_to_stacked_ar()\n",
    "            \n",
    "        return observation, reward, terminated,\n",
    "            \n",
    "            \n",
    "\n",
    "    def reset_env(self):\n",
    "        \"\"\"\n",
    "        Reset the environment to the initial state.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.current_state = self.env.reset()[0]\n",
    "        self.frames = [deque([self.process_frame(init_frame) for _ in range(4)]) for init_frame in self.current_state]\n",
    "        \n",
    "    def sample(self, n_samples, epsilon=0.2):\n",
    "        \"\"\"\n",
    "        Sample environment data.\n",
    "\n",
    "        Args:\n",
    "            n_samples: The number of samples to generate.\n",
    "            epsilon: The exploration factor for action selection (default: 0.2).\n",
    "\n",
    "        Returns:\n",
    "            samples: List of sampled data tuples (current_state, next_state, action, reward, terminated).\n",
    "        \"\"\"\n",
    "        samples = []\n",
    "\n",
    "        n_steps = np.ceil(n_samples / self.n_multi_envs).astype(int)\n",
    "\n",
    "        for _ in range(n_steps):\n",
    "\n",
    "\n",
    "            action, q_vals = map(lambda x: x.numpy(), sample_trajectory(\n",
    "                self.dqn, tf.convert_to_tensor( self.last_observation), epsilon))\n",
    "\n",
    "            observation, reward, terminated,  = self.step(\n",
    "                action)\n",
    "\n",
    "            for i in range(self.n_multi_envs):\n",
    "                samples.append((self.last_observation[i],\n",
    "                                observation[i],\n",
    "                                action[i],\n",
    "                                reward[i],\n",
    "                                terminated[i]))\n",
    "\n",
    "            self.last_observation = observation\n",
    "\n",
    "        return samples[:n_samples]\n",
    "\n",
    "\n",
    "def measure_model_perforamnce(dqn, target_q, n_test_envs = 4):\n",
    "\n",
    "        test_env = ENV_SAMPLER(dqn, n_multi_envs=n_test_envs)\n",
    "\n",
    "        last_observation = test_env.last_observation\n",
    "\n",
    "\n",
    "        rewards = np.zeros(n_test_envs)\n",
    "        terminated_at = []\n",
    "        q_values = []\n",
    "        target_q_values = []\n",
    "\n",
    "        allready_terminated = np.zeros(n_test_envs, bool)\n",
    "\n",
    "        steps = 0\n",
    "\n",
    "        while True:\n",
    "            \n",
    "            action, q_vals = map(lambda x: x.numpy(), sample_trajectory(\n",
    "                dqn, tf.convert_to_tensor(last_observation), 0.05))\n",
    "\n",
    "            target_vals = tf.reduce_max(target_q(last_observation), -1)\n",
    "\n",
    "            observation, reward, terminated = test_env.step(\n",
    "                action)\n",
    "\n",
    "            last_observation = observation\n",
    "\n",
    "            rewards += reward * (1 - allready_terminated)\n",
    "\n",
    "\n",
    "            allready_terminated = np.logical_or(\n",
    "                allready_terminated, terminated)\n",
    "\n",
    "            for index,t in enumerate(terminated):\n",
    "\n",
    "                if t:\n",
    "                    terminated_at.append(steps)\n",
    "\n",
    "            q_values.extend(q_vals.tolist())\n",
    "            target_q_values.extend(target_vals.numpy().tolist())\n",
    "\n",
    "            steps += 1\n",
    "\n",
    "            if allready_terminated.all():\n",
    "\n",
    "                break\n",
    "\n",
    "        average_q_val = np.mean(q_values)\n",
    "        average_target_q_val = np.mean(target_q_values)\n",
    "\n",
    "        l2_diff = np.array(q_values) - np.array(target_q_values)\n",
    "        l2_diff = np.sqrt(np.square(l2_diff).mean())\n",
    "\n",
    "        average_rewards = np.mean(rewards)\n",
    "        average_termination = np.mean(terminated_at)\n",
    "        \n",
    "        test_env.env.close()\n",
    "        \n",
    "        del test_env\n",
    "\n",
    "        return average_rewards, average_termination, average_q_val, average_target_q_val, l2_diff\n",
    "\n",
    "\n",
    "\n",
    "def get_standard_dqn():\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    inputs = tf.keras.layers.Input((84,84, 4))\n",
    "\n",
    "    x = triple_conv_block_no_batchnorm(inputs, 16)\n",
    "    x = tf.keras.layers.MaxPool2D(2)(x)\n",
    "    x = triple_conv_block_no_batchnorm(x, 32)\n",
    "    x = tf.keras.layers.MaxPool2D(2)(x)\n",
    "    x = triple_conv_block_no_batchnorm(x, 64)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dense(512, \"relu\")(x)\n",
    "    outputs = tf.keras.layers.Dense(4, \"linear\")(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"standard_dqn\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def preprocess_all(observation, next_observation, action, reward, terminated):\n",
    "\n",
    "    observation = tf.cast(observation, tf.float32)\n",
    "    next_observation = tf.cast(next_observation, tf.float32)\n",
    "\n",
    "    action = tf.cast(action, tf.int64)\n",
    "    reward = tf.cast(reward, tf.float32)\n",
    "    terminated = tf.cast(terminated, tf.bool)\n",
    "\n",
    "    return observation, next_observation, action, reward, terminated\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def polyak_averaging(Q_target, Q_dqn, tau):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        Q_target (_type_): _description_\n",
    "        Q_dqn (_type_): _description_\n",
    "        tau (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    for old, new in zip(Q_target.trainable_variables, Q_dqn.trainable_variables):\n",
    "        update = old * (1 - tau) + new * tau\n",
    "        old.assign(update)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def update_q_network(data, dqn, q_target, optimizer, gamma):\n",
    "\n",
    "    state, next_state, action, reward, terminated = data\n",
    "\n",
    "    s_prime_values = q_target(next_state, training=False)\n",
    "    s_prime_values = tf.reduce_max(s_prime_values, -1)\n",
    "    \n",
    "    punishment = tf.ones_like(reward) * -1\n",
    "    labels = reward + gamma * s_prime_values\n",
    "    \n",
    "    labels = tf.where(terminated, punishment, labels)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        predictions = dqn(state, training=True)\n",
    "        action_values = tf.gather(predictions, action, batch_dims=1)\n",
    "\n",
    "        loss = LOSS(action_values, labels)\n",
    "\n",
    "    gradients = tape.gradient(loss, dqn.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, dqn.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    \"\"\"\n",
    "    Class for managing a replay buffer for reinforcement learning.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the ReplayBuffer instance.\n",
    "\n",
    "        Args:\n",
    "            preprocess_func: Function to preprocess examples.\n",
    "        \"\"\"\n",
    "        self.saved_trajectories = []\n",
    "\n",
    "    def add_new_trajectory(self, trajectory):\n",
    "        \"\"\"\n",
    "        Add a new trajectory to the replay buffer.\n",
    "\n",
    "        Args:\n",
    "            trajectory: List of examples representing a trajectory.\n",
    "        \"\"\"\n",
    "        self.saved_trajectories.append(trajectory)\n",
    "\n",
    "    def drop_first_trajectory(self):\n",
    "        \"\"\"\n",
    "        Remove the oldest trajectory from the replay buffer.\n",
    "        \"\"\"\n",
    "        to_delete = self.saved_trajectories.pop(0)\n",
    "        del to_delete\n",
    "\n",
    "    def sample_singe_example(\n",
    "        self,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Sample a single example from the replay buffer.\n",
    "\n",
    "        Args:\n",
    "            melt_stop_criteria: Boolean flag indicating whether to consider stop criteria (default: False).\n",
    "\n",
    "        Returns:\n",
    "            example: A single example from a randomly chosen trajectory.\n",
    "        \"\"\"\n",
    "        trajectory = random.choice(self.saved_trajectories)\n",
    "        example = random.choice(trajectory)\n",
    "\n",
    "        states, next_states, actions, rewards, terminations, = example\n",
    "\n",
    "        return states, next_states, actions, rewards, terminations\n",
    "\n",
    "    def sample_n_examples(self, n_examples: int):\n",
    "        \"\"\"\n",
    "        Sample multiple examples from the replay buffer.\n",
    "\n",
    "        Args:\n",
    "            n_examples: The number of examples to sample.\n",
    "\n",
    "        Returns:\n",
    "            states, next_states, actions, rewards, stop_criteria: Arrays of sampled examples.\n",
    "        \"\"\"\n",
    "        trajectories = [self.sample_singe_example() for _ in range(n_examples)]\n",
    "\n",
    "        states, next_states, actions, rewards, stop_criteria = map(\n",
    "            np.array, zip(*trajectories)\n",
    "        )\n",
    "\n",
    "        return states, next_states, actions, rewards, stop_criteria\n",
    "\n",
    "    def generate_tf_dataset(self, n_batches, batchsize):\n",
    "        \"\"\"\n",
    "        Generate a TensorFlow dataset from the replay buffer.\n",
    "\n",
    "        Args:\n",
    "            n_batches: The number of batches to generate.\n",
    "            batchsize: The size of each batch.\n",
    "\n",
    "        Returns:\n",
    "            ds: TensorFlow dataset containing the preprocessed examples.\n",
    "        \"\"\"\n",
    "        n_steps = n_batches * batchsize\n",
    "\n",
    "        ds = self.sample_n_examples(n_steps)\n",
    "        ds = tf.data.Dataset.from_tensor_slices(ds)\n",
    "        ds = ds.map(preprocess_all, tf.data.AUTOTUNE)\n",
    "        ds = ds.batch(batchsize)\n",
    "\n",
    "        return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 17:44:41.368174: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-20 17:44:41.372391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-20 17:44:41.372553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-20 17:44:41.374043: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-20 17:44:41.374344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-20 17:44:41.374483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-20 17:44:41.374601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-20 17:44:42.619743: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-20 17:44:42.619922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-20 17:44:42.620050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-20 17:44:42.620926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6701 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fe1681d9630>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00025, clipnorm=1.0)\n",
    "\n",
    "q_net = get_standard_dqn()\n",
    "\n",
    "target_net = tf.keras.models.clone_model(q_net)\n",
    "\n",
    "env_sampler = ENV_SAMPLER(q_net, N_MULTI_ENVS)\n",
    "replay_buffer = ReplayBuffer()\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(q_net = q_net, target_net = target_net, optimizer = optimizer)\n",
    "\n",
    "writer = tf.summary.create_file_writer(TB_LOGS)\n",
    "\n",
    "# restore\n",
    "checkpoint.restore(\"breakout/ckps/ckpt-105\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fill Buffer initally:   0%|          | 0/100 [00:00<?, ?it/s]2023-06-20 17:44:46.626240: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n",
      "2023-06-20 17:44:48.092728: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-06-20 17:44:48.093305: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-06-20 17:44:48.093323: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-06-20 17:44:48.093796: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-06-20 17:44:48.093839: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "Fill Buffer initally: 100%|| 100/100 [00:33<00:00,  2.98it/s]\n"
     ]
    }
   ],
   "source": [
    "for _ in tqdm.tqdm(range(N_SAMPLE_SETS), desc = \"Fill Buffer initally\"):\n",
    "\n",
    "    new_samples = env_sampler.sample(N_NEW_SAMPLES, epsilon = EXPLORATION_RATE)\n",
    "    replay_buffer.add_new_trajectory(new_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging Model Metrics\n",
      "average_rewards           39.750000\n",
      "average_termination     1133.250000\n",
      "average_q_val              2.369098\n",
      "average_target_q_val       2.384071\n",
      "l2_diff                    0.044927\n",
      "average_loss               0.042320\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           73.875000\n",
      "average_termination     1418.875000\n",
      "average_q_val              2.529731\n",
      "average_target_q_val       2.568625\n",
      "l2_diff                    0.052752\n",
      "average_loss               0.041058\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           72.250000\n",
      "average_termination     1362.375000\n",
      "average_q_val              2.563657\n",
      "average_target_q_val       2.560974\n",
      "l2_diff                    0.032611\n",
      "average_loss               0.032521\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           47.750000\n",
      "average_termination     1140.125000\n",
      "average_q_val              2.572621\n",
      "average_target_q_val       2.530312\n",
      "l2_diff                    0.058379\n",
      "average_loss               0.026650\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards          39.000000\n",
      "average_termination     955.000000\n",
      "average_q_val             2.404737\n",
      "average_target_q_val      2.393965\n",
      "l2_diff                   0.037634\n",
      "average_loss              0.044331\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           56.000000\n",
      "average_termination     1308.125000\n",
      "average_q_val              2.416733\n",
      "average_target_q_val       2.411508\n",
      "l2_diff                    0.039137\n",
      "average_loss               0.036593\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           52.375000\n",
      "average_termination     1206.875000\n",
      "average_q_val              2.413821\n",
      "average_target_q_val       2.419507\n",
      "l2_diff                    0.034268\n",
      "average_loss               0.034304\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           53.750000\n",
      "average_termination     1204.625000\n",
      "average_q_val              2.527342\n",
      "average_target_q_val       2.513379\n",
      "l2_diff                    0.051747\n",
      "average_loss               0.033630\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards          31.125000\n",
      "average_termination     867.250000\n",
      "average_q_val             2.410412\n",
      "average_target_q_val      2.432410\n",
      "l2_diff                   0.043421\n",
      "average_loss              0.035867\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           67.500000\n",
      "average_termination     1396.000000\n",
      "average_q_val              2.529913\n",
      "average_target_q_val       2.521788\n",
      "l2_diff                    0.044510\n",
      "average_loss               0.024826\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           67.250000\n",
      "average_termination     1412.375000\n",
      "average_q_val              2.596519\n",
      "average_target_q_val       2.626773\n",
      "l2_diff                    0.049604\n",
      "average_loss               0.026920\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           68.875000\n",
      "average_termination     1365.625000\n",
      "average_q_val              2.722571\n",
      "average_target_q_val       2.697764\n",
      "l2_diff                    0.040933\n",
      "average_loss               0.033779\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           75.750000\n",
      "average_termination     1349.125000\n",
      "average_q_val              2.778596\n",
      "average_target_q_val       2.756516\n",
      "l2_diff                    0.056313\n",
      "average_loss               0.029171\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           47.375000\n",
      "average_termination     1133.625000\n",
      "average_q_val              2.622164\n",
      "average_target_q_val       2.616128\n",
      "l2_diff                    0.035902\n",
      "average_loss               0.028474\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           35.250000\n",
      "average_termination     1055.875000\n",
      "average_q_val              2.611394\n",
      "average_target_q_val       2.595084\n",
      "l2_diff                    0.047295\n",
      "average_loss               0.038639\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           58.000000\n",
      "average_termination     1375.625000\n",
      "average_q_val              2.621641\n",
      "average_target_q_val       2.622375\n",
      "l2_diff                    0.035320\n",
      "average_loss               0.028102\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           54.625000\n",
      "average_termination     1139.625000\n",
      "average_q_val              2.710428\n",
      "average_target_q_val       2.722467\n",
      "l2_diff                    0.037725\n",
      "average_loss               0.027028\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           60.125000\n",
      "average_termination     1293.125000\n",
      "average_q_val              2.824393\n",
      "average_target_q_val       2.774647\n",
      "l2_diff                    0.066306\n",
      "average_loss               0.028456\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           54.625000\n",
      "average_termination     1202.875000\n",
      "average_q_val              2.788973\n",
      "average_target_q_val       2.789707\n",
      "l2_diff                    0.040174\n",
      "average_loss               0.027108\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           51.125000\n",
      "average_termination     1152.375000\n",
      "average_q_val              2.847341\n",
      "average_target_q_val       2.823929\n",
      "l2_diff                    0.045509\n",
      "average_loss               0.040172\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           55.750000\n",
      "average_termination     1185.500000\n",
      "average_q_val              2.827579\n",
      "average_target_q_val       2.791866\n",
      "l2_diff                    0.067714\n",
      "average_loss               0.060002\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards          36.250000\n",
      "average_termination     916.875000\n",
      "average_q_val             2.767561\n",
      "average_target_q_val      2.790234\n",
      "l2_diff                   0.054030\n",
      "average_loss              0.036696\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           44.625000\n",
      "average_termination     1174.375000\n",
      "average_q_val              2.673409\n",
      "average_target_q_val       2.673896\n",
      "l2_diff                    0.044325\n",
      "average_loss               0.039533\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           53.625000\n",
      "average_termination     1335.625000\n",
      "average_q_val              2.786050\n",
      "average_target_q_val       2.755198\n",
      "l2_diff                    0.063071\n",
      "average_loss               0.038732\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards          36.750000\n",
      "average_termination     996.000000\n",
      "average_q_val             2.744624\n",
      "average_target_q_val      2.757115\n",
      "l2_diff                   0.047061\n",
      "average_loss              0.043923\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           42.625000\n",
      "average_termination     1089.666667\n",
      "average_q_val              2.782208\n",
      "average_target_q_val       2.783215\n",
      "l2_diff                    0.034581\n",
      "average_loss               0.025785\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           57.250000\n",
      "average_termination     1158.125000\n",
      "average_q_val              3.025874\n",
      "average_target_q_val       2.994733\n",
      "l2_diff                    0.054056\n",
      "average_loss               0.030384\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           71.625000\n",
      "average_termination     1401.125000\n",
      "average_q_val              2.830752\n",
      "average_target_q_val       2.875633\n",
      "l2_diff                    0.056499\n",
      "average_loss               0.035690\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           49.250000\n",
      "average_termination     1175.875000\n",
      "average_q_val              2.863117\n",
      "average_target_q_val       2.851767\n",
      "l2_diff                    0.050579\n",
      "average_loss               0.043233\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           60.000000\n",
      "average_termination     1190.000000\n",
      "average_q_val              2.940382\n",
      "average_target_q_val       2.922628\n",
      "l2_diff                    0.040879\n",
      "average_loss               0.049537\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards          30.500000\n",
      "average_termination     876.125000\n",
      "average_q_val             2.707190\n",
      "average_target_q_val      2.681534\n",
      "l2_diff                   0.053263\n",
      "average_loss              0.031157\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           63.375000\n",
      "average_termination     1278.888889\n",
      "average_q_val              2.912128\n",
      "average_target_q_val       2.879173\n",
      "l2_diff                    0.053078\n",
      "average_loss               0.042839\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           51.250000\n",
      "average_termination     1195.625000\n",
      "average_q_val              2.834770\n",
      "average_target_q_val       2.796967\n",
      "l2_diff                    0.064286\n",
      "average_loss               0.029724\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           65.125000\n",
      "average_termination     1408.250000\n",
      "average_q_val              3.053232\n",
      "average_target_q_val       3.013132\n",
      "l2_diff                    0.055869\n",
      "average_loss               0.032993\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards          24.750000\n",
      "average_termination     874.909091\n",
      "average_q_val             2.859215\n",
      "average_target_q_val      2.879263\n",
      "l2_diff                   0.052330\n",
      "average_loss              0.038733\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           69.250000\n",
      "average_termination     1300.625000\n",
      "average_q_val              2.982296\n",
      "average_target_q_val       2.955084\n",
      "l2_diff                    0.044570\n",
      "average_loss               0.044453\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           46.750000\n",
      "average_termination     1117.250000\n",
      "average_q_val              2.911628\n",
      "average_target_q_val       2.886031\n",
      "l2_diff                    0.045725\n",
      "average_loss               0.038872\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           79.125000\n",
      "average_termination     1423.250000\n",
      "average_q_val              3.019618\n",
      "average_target_q_val       3.040756\n",
      "l2_diff                    0.043259\n",
      "average_loss               0.030228\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           52.000000\n",
      "average_termination     1045.000000\n",
      "average_q_val              3.011594\n",
      "average_target_q_val       3.031673\n",
      "l2_diff                    0.042721\n",
      "average_loss               0.050397\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           66.375000\n",
      "average_termination     1313.000000\n",
      "average_q_val              3.016187\n",
      "average_target_q_val       3.000346\n",
      "l2_diff                    0.037854\n",
      "average_loss               0.034140\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           52.500000\n",
      "average_termination     1276.500000\n",
      "average_q_val              2.979168\n",
      "average_target_q_val       3.003776\n",
      "l2_diff                    0.057465\n",
      "average_loss               0.044351\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards          23.750000\n",
      "average_termination     824.888889\n",
      "average_q_val             2.828015\n",
      "average_target_q_val      2.806166\n",
      "l2_diff                   0.054848\n",
      "average_loss              0.051948\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           47.000000\n",
      "average_termination     1002.625000\n",
      "average_q_val              2.913444\n",
      "average_target_q_val       2.907045\n",
      "l2_diff                    0.040556\n",
      "average_loss               0.028410\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           51.875000\n",
      "average_termination     1366.625000\n",
      "average_q_val              2.990054\n",
      "average_target_q_val       2.952751\n",
      "l2_diff                    0.067929\n",
      "average_loss               0.045714\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           39.875000\n",
      "average_termination     1109.875000\n",
      "average_q_val              2.828618\n",
      "average_target_q_val       2.802917\n",
      "l2_diff                    0.052298\n",
      "average_loss               0.041813\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           48.625000\n",
      "average_termination     1143.333333\n",
      "average_q_val              3.056861\n",
      "average_target_q_val       3.019047\n",
      "l2_diff                    0.065336\n",
      "average_loss               0.041029\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           68.000000\n",
      "average_termination     1471.500000\n",
      "average_q_val              3.101824\n",
      "average_target_q_val       3.111146\n",
      "l2_diff                    0.048326\n",
      "average_loss               0.039147\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           71.000000\n",
      "average_termination     1311.750000\n",
      "average_q_val              3.158421\n",
      "average_target_q_val       3.103102\n",
      "l2_diff                    0.071997\n",
      "average_loss               0.027297\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           50.375000\n",
      "average_termination     1199.250000\n",
      "average_q_val              2.955491\n",
      "average_target_q_val       2.946699\n",
      "l2_diff                    0.047845\n",
      "average_loss               0.034345\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           51.000000\n",
      "average_termination     1027.750000\n",
      "average_q_val              3.284365\n",
      "average_target_q_val       3.208860\n",
      "l2_diff                    0.090329\n",
      "average_loss               0.049962\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           50.625000\n",
      "average_termination     1203.666667\n",
      "average_q_val              3.012378\n",
      "average_target_q_val       3.010870\n",
      "l2_diff                    0.034450\n",
      "average_loss               0.038557\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           49.250000\n",
      "average_termination     1101.250000\n",
      "average_q_val              3.110119\n",
      "average_target_q_val       3.159685\n",
      "l2_diff                    0.062486\n",
      "average_loss               0.035465\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           71.500000\n",
      "average_termination     1382.125000\n",
      "average_q_val              3.138196\n",
      "average_target_q_val       3.168580\n",
      "l2_diff                    0.050763\n",
      "average_loss               0.034757\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           45.875000\n",
      "average_termination     1117.500000\n",
      "average_q_val              2.962021\n",
      "average_target_q_val       2.958400\n",
      "l2_diff                    0.041668\n",
      "average_loss               0.028955\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards          37.500000\n",
      "average_termination     966.500000\n",
      "average_q_val             3.062978\n",
      "average_target_q_val      3.035894\n",
      "l2_diff                   0.045493\n",
      "average_loss              0.041073\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           72.250000\n",
      "average_termination     1401.375000\n",
      "average_q_val              3.177377\n",
      "average_target_q_val       3.120275\n",
      "l2_diff                    0.069811\n",
      "average_loss               0.046739\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards          100.875000\n",
      "average_termination     1457.500000\n",
      "average_q_val              3.252807\n",
      "average_target_q_val       3.227363\n",
      "l2_diff                    0.050926\n",
      "average_loss               0.034112\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           49.125000\n",
      "average_termination     1102.375000\n",
      "average_q_val              3.058149\n",
      "average_target_q_val       3.029471\n",
      "l2_diff                    0.046251\n",
      "average_loss               0.040461\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards          114.000000\n",
      "average_termination     1376.750000\n",
      "average_q_val              3.284599\n",
      "average_target_q_val       3.251859\n",
      "l2_diff                    0.047884\n",
      "average_loss               0.057162\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards          150.625000\n",
      "average_termination     1658.125000\n",
      "average_q_val              3.124765\n",
      "average_target_q_val       3.155314\n",
      "l2_diff                    0.052080\n",
      "average_loss               0.038911\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards          121.125000\n",
      "average_termination     1545.111111\n",
      "average_q_val              3.156485\n",
      "average_target_q_val       3.116662\n",
      "l2_diff                    0.054832\n",
      "average_loss               0.041413\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           44.000000\n",
      "average_termination     1042.444444\n",
      "average_q_val              2.961538\n",
      "average_target_q_val       2.949157\n",
      "l2_diff                    0.047752\n",
      "average_loss               0.048116\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           75.500000\n",
      "average_termination     1430.500000\n",
      "average_q_val              3.184662\n",
      "average_target_q_val       3.209632\n",
      "l2_diff                    0.047099\n",
      "average_loss               0.040463\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           64.500000\n",
      "average_termination     1437.333333\n",
      "average_q_val              3.117298\n",
      "average_target_q_val       3.134956\n",
      "l2_diff                    0.037563\n",
      "average_loss               0.036053\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           66.875000\n",
      "average_termination     1277.500000\n",
      "average_q_val              3.179523\n",
      "average_target_q_val       3.198986\n",
      "l2_diff                    0.049868\n",
      "average_loss               0.054771\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           40.125000\n",
      "average_termination     1116.000000\n",
      "average_q_val              3.119108\n",
      "average_target_q_val       3.119088\n",
      "l2_diff                    0.045148\n",
      "average_loss               0.044155\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           43.500000\n",
      "average_termination     1014.375000\n",
      "average_q_val              3.108057\n",
      "average_target_q_val       3.108270\n",
      "l2_diff                    0.042787\n",
      "average_loss               0.047758\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           77.375000\n",
      "average_termination     1180.333333\n",
      "average_q_val              2.981773\n",
      "average_target_q_val       2.986439\n",
      "l2_diff                    0.060677\n",
      "average_loss               0.049264\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           85.250000\n",
      "average_termination     1384.875000\n",
      "average_q_val              3.234661\n",
      "average_target_q_val       3.220878\n",
      "l2_diff                    0.047694\n",
      "average_loss               0.043658\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           46.125000\n",
      "average_termination     1177.400000\n",
      "average_q_val              3.109632\n",
      "average_target_q_val       3.110716\n",
      "l2_diff                    0.049957\n",
      "average_loss               0.043938\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           58.500000\n",
      "average_termination     1237.888889\n",
      "average_q_val              3.189302\n",
      "average_target_q_val       3.237333\n",
      "l2_diff                    0.068254\n",
      "average_loss               0.060225\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           50.875000\n",
      "average_termination     1169.666667\n",
      "average_q_val              3.155186\n",
      "average_target_q_val       3.131018\n",
      "l2_diff                    0.059239\n",
      "average_loss               0.075812\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           32.375000\n",
      "average_termination     1064.272727\n",
      "average_q_val              3.062393\n",
      "average_target_q_val       3.063969\n",
      "l2_diff                    0.053342\n",
      "average_loss               0.043201\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards          43.500000\n",
      "average_termination     992.500000\n",
      "average_q_val             3.186094\n",
      "average_target_q_val      3.196195\n",
      "l2_diff                   0.040472\n",
      "average_loss              0.052595\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards          113.250000\n",
      "average_termination     1507.375000\n",
      "average_q_val              3.386937\n",
      "average_target_q_val       3.389256\n",
      "l2_diff                    0.044098\n",
      "average_loss               0.034347\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards          134.750000\n",
      "average_termination     1448.750000\n",
      "average_q_val              3.322105\n",
      "average_target_q_val       3.341057\n",
      "l2_diff                    0.039339\n",
      "average_loss               0.046425\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           53.000000\n",
      "average_termination     1200.250000\n",
      "average_q_val              3.204627\n",
      "average_target_q_val       3.232868\n",
      "l2_diff                    0.057757\n",
      "average_loss               0.046291\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           75.125000\n",
      "average_termination     1354.000000\n",
      "average_q_val              3.389970\n",
      "average_target_q_val       3.376295\n",
      "l2_diff                    0.047234\n",
      "average_loss               0.039257\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           78.875000\n",
      "average_termination     1455.375000\n",
      "average_q_val              3.268824\n",
      "average_target_q_val       3.268622\n",
      "l2_diff                    0.044125\n",
      "average_loss               0.070344\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards          29.125000\n",
      "average_termination     837.222222\n",
      "average_q_val             2.990672\n",
      "average_target_q_val      3.009215\n",
      "l2_diff                   0.068350\n",
      "average_loss              0.055160\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           59.750000\n",
      "average_termination     1152.250000\n",
      "average_q_val              3.345174\n",
      "average_target_q_val       3.340087\n",
      "l2_diff                    0.045137\n",
      "average_loss               0.066375\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           98.250000\n",
      "average_termination     1457.875000\n",
      "average_q_val              3.408496\n",
      "average_target_q_val       3.398567\n",
      "l2_diff                    0.038920\n",
      "average_loss               0.029786\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           42.375000\n",
      "average_termination     1069.000000\n",
      "average_q_val              3.225072\n",
      "average_target_q_val       3.202518\n",
      "l2_diff                    0.042566\n",
      "average_loss               0.060785\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           92.875000\n",
      "average_termination     1449.750000\n",
      "average_q_val              3.458712\n",
      "average_target_q_val       3.443473\n",
      "l2_diff                    0.049081\n",
      "average_loss               0.052089\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           91.375000\n",
      "average_termination     1468.875000\n",
      "average_q_val              3.448613\n",
      "average_target_q_val       3.396436\n",
      "l2_diff                    0.061970\n",
      "average_loss               0.048348\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           62.250000\n",
      "average_termination     1342.375000\n",
      "average_q_val              3.295837\n",
      "average_target_q_val       3.311743\n",
      "l2_diff                    0.059536\n",
      "average_loss               0.062120\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           69.875000\n",
      "average_termination     1357.750000\n",
      "average_q_val              3.160576\n",
      "average_target_q_val       3.168404\n",
      "l2_diff                    0.048602\n",
      "average_loss               0.044745\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           68.000000\n",
      "average_termination     1260.777778\n",
      "average_q_val              3.135443\n",
      "average_target_q_val       3.170896\n",
      "l2_diff                    0.059805\n",
      "average_loss               0.048009\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           61.875000\n",
      "average_termination     1277.000000\n",
      "average_q_val              3.347414\n",
      "average_target_q_val       3.347276\n",
      "l2_diff                    0.050024\n",
      "average_loss               0.048183\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           81.250000\n",
      "average_termination     1421.625000\n",
      "average_q_val              3.324650\n",
      "average_target_q_val       3.356652\n",
      "l2_diff                    0.051967\n",
      "average_loss               0.071432\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards          40.125000\n",
      "average_termination     987.250000\n",
      "average_q_val             3.271643\n",
      "average_target_q_val      3.272403\n",
      "l2_diff                   0.061268\n",
      "average_loss              0.031772\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           40.125000\n",
      "average_termination     1154.625000\n",
      "average_q_val              3.038325\n",
      "average_target_q_val       3.049631\n",
      "l2_diff                    0.057568\n",
      "average_loss               0.051113\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           91.125000\n",
      "average_termination     1379.750000\n",
      "average_q_val              3.438583\n",
      "average_target_q_val       3.437166\n",
      "l2_diff                    0.037436\n",
      "average_loss               0.060619\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards          35.500000\n",
      "average_termination     896.375000\n",
      "average_q_val             3.255377\n",
      "average_target_q_val      3.226248\n",
      "l2_diff                   0.064326\n",
      "average_loss              0.064663\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards          111.750000\n",
      "average_termination     1581.250000\n",
      "average_q_val              3.453452\n",
      "average_target_q_val       3.429548\n",
      "l2_diff                    0.061115\n",
      "average_loss               0.041285\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           83.125000\n",
      "average_termination     1299.750000\n",
      "average_q_val              3.467466\n",
      "average_target_q_val       3.427619\n",
      "l2_diff                    0.063211\n",
      "average_loss               0.024900\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           78.500000\n",
      "average_termination     1294.000000\n",
      "average_q_val              3.400488\n",
      "average_target_q_val       3.384957\n",
      "l2_diff                    0.056365\n",
      "average_loss               0.069812\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards          100.750000\n",
      "average_termination     1294.500000\n",
      "average_q_val              3.501345\n",
      "average_target_q_val       3.477406\n",
      "l2_diff                    0.045943\n",
      "average_loss               0.053620\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           88.000000\n",
      "average_termination     1306.750000\n",
      "average_q_val              3.415171\n",
      "average_target_q_val       3.385828\n",
      "l2_diff                    0.064598\n",
      "average_loss               0.046055\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards          106.750000\n",
      "average_termination     1431.000000\n",
      "average_q_val              3.495216\n",
      "average_target_q_val       3.449800\n",
      "l2_diff                    0.059376\n",
      "average_loss               0.050257\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           62.750000\n",
      "average_termination     1243.500000\n",
      "average_q_val              3.469622\n",
      "average_target_q_val       3.470733\n",
      "l2_diff                    0.062340\n",
      "average_loss               0.043449\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           69.125000\n",
      "average_termination     1373.000000\n",
      "average_q_val              3.516015\n",
      "average_target_q_val       3.456281\n",
      "l2_diff                    0.075882\n",
      "average_loss               0.046907\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           59.250000\n",
      "average_termination     1246.000000\n",
      "average_q_val              3.457009\n",
      "average_target_q_val       3.452799\n",
      "l2_diff                    0.035852\n",
      "average_loss               0.047022\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           78.500000\n",
      "average_termination     1418.750000\n",
      "average_q_val              3.452076\n",
      "average_target_q_val       3.473965\n",
      "l2_diff                    0.046484\n",
      "average_loss               0.040940\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards          103.250000\n",
      "average_termination     1389.750000\n",
      "average_q_val              3.494711\n",
      "average_target_q_val       3.482181\n",
      "l2_diff                    0.053616\n",
      "average_loss               0.035733\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards          39.000000\n",
      "average_termination     985.500000\n",
      "average_q_val             3.421775\n",
      "average_target_q_val      3.422835\n",
      "l2_diff                   0.047201\n",
      "average_loss              0.040694\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           82.000000\n",
      "average_termination     1365.750000\n",
      "average_q_val              3.537211\n",
      "average_target_q_val       3.511332\n",
      "l2_diff                    0.058424\n",
      "average_loss               0.038917\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           58.000000\n",
      "average_termination     1193.222222\n",
      "average_q_val              3.300322\n",
      "average_target_q_val       3.322240\n",
      "l2_diff                    0.053164\n",
      "average_loss               0.069937\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards          105.750000\n",
      "average_termination     1507.625000\n",
      "average_q_val              3.513317\n",
      "average_target_q_val       3.526045\n",
      "l2_diff                    0.043470\n",
      "average_loss               0.050013\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           60.375000\n",
      "average_termination     1470.875000\n",
      "average_q_val              3.388881\n",
      "average_target_q_val       3.389924\n",
      "l2_diff                    0.040196\n",
      "average_loss               0.051984\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           91.875000\n",
      "average_termination     1360.500000\n",
      "average_q_val              3.524084\n",
      "average_target_q_val       3.536759\n",
      "l2_diff                    0.037321\n",
      "average_loss               0.054322\n",
      "dtype: float64\n",
      "Saving Checkpoint\n",
      "Logging Model Metrics\n",
      "average_rewards           79.625000\n",
      "average_termination     1317.125000\n",
      "average_q_val              3.552492\n",
      "average_target_q_val       3.496093\n",
      "l2_diff                    0.072781\n",
      "average_loss               0.057667\n",
      "dtype: float64\n",
      "Saving Checkpoint\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m losses \u001b[39m=\u001b[39m []\n\u001b[1;32m     18\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m bar:\n\u001b[0;32m---> 20\u001b[0m     loss \u001b[39m=\u001b[39m update_q_network(data, q_net, target_net, optimizer, GAMMA)\n\u001b[1;32m     22\u001b[0m     losses\u001b[39m.\u001b[39mappend(loss)\n\u001b[1;32m     23\u001b[0m     mean_loss \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(np\u001b[39m.\u001b[39mmean(losses))\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2957\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1854\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "outer_steps = 10733\n",
    "\n",
    "\n",
    "while True:\n",
    "    \n",
    "\n",
    "    outer_steps +=1\n",
    "    EXPLORATION_RATE *= EPSILON_DECAY\n",
    "    EXPLORATION_RATE = max(EXPLORATION_RATE, 0.1)\n",
    "    \n",
    "    ds = replay_buffer.sample_n_examples(1000)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(ds)\n",
    "    ds = ds.map(preprocess_all, tf.data.AUTOTUNE).batch(BATCHSIZE)\n",
    "    bar = ds # tqdm.tqdm(ds)\n",
    "    \n",
    "    losses = []\n",
    "\n",
    "    for data in bar:\n",
    "\n",
    "        loss = update_q_network(data, q_net, target_net, optimizer, GAMMA)\n",
    "        \n",
    "        losses.append(loss)\n",
    "        mean_loss = float(np.mean(losses))\n",
    "        # bar.set_description(f\"Loss {mean_loss:.6f}\")\n",
    "\n",
    "    mean_loss = float(np.mean(losses))\n",
    "    \n",
    "    with writer.as_default():\n",
    "\n",
    "        tf.summary.scalar(\"loss\", mean_loss, step=outer_steps)\n",
    "        tf.summary.scalar(\"epsilon\", EXPLORATION_RATE, step=outer_steps)\n",
    "\n",
    "\n",
    "    new_samples = env_sampler.sample(N_NEW_SAMPLES, epsilon= EXPLORATION_RATE)\n",
    "    replay_buffer.add_new_trajectory(new_samples)\n",
    "\n",
    "    replay_buffer.drop_first_trajectory()\n",
    "\n",
    "    polyak_averaging(target_net, q_net, TAU)\n",
    "    \n",
    "    \n",
    "    if outer_steps % LOG_FREQ == 0:\n",
    "        \n",
    "        print(\"Logging Model Metrics\")\n",
    "        \n",
    "        results = measure_model_perforamnce( q_net, target_net, N_TEST_ENVS)\n",
    "        names = [\"average_rewards\", \"average_termination\", \"average_q_val\", \"average_target_q_val\", \"l2_diff\",]\n",
    "\n",
    "        for val, name in zip(results, names):\n",
    "\n",
    "            with writer.as_default():\n",
    "\n",
    "                tf.summary.scalar(name, val, step=outer_steps)\n",
    "\n",
    "        results = pd.Series(results, names)\n",
    "        \n",
    "        results[\"average_loss\"] = np.mean(losses)\n",
    "        \n",
    "        results.to_json(TMP_LOG_PATH.format(outer_steps))\n",
    "        \n",
    "        print(results)\n",
    "        \n",
    "        \n",
    "    if outer_steps % CHECKPOINT_FREQ == 0:\n",
    "        \n",
    "        print(\"Saving Checkpoint\")\n",
    "        \n",
    "        checkpoint.save(TMP_SAVE_TO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
